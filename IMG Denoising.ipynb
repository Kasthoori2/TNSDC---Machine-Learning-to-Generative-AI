{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "2VuFpcQQN0MG",
        "outputId": "1c5fbb7c-8569-4c4f-9fca-035a3051b400"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (<ipython-input-1-fcf4bf6eca92>, line 49)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-fcf4bf6eca92>\"\u001b[0;36m, line \u001b[0;32m49\u001b[0m\n\u001b[0;31m    if __name__==\"__main__\"\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, request, jsonify, send_file\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import scipy.misc\n",
        "\n",
        "import base64\n",
        "\n",
        "from io import BytesIO\n",
        "\n",
        "from test import *\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "\n",
        "def index():\n",
        "\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/denoisify', methods=['GET', 'POST'])\n",
        "\n",
        "def denoisify():\n",
        "\n",
        "    if request.method == \"POST\":\n",
        "\n",
        "        inputImg = request.files['file']\n",
        "\n",
        "        outputImg = denoise(inputImg)\n",
        "\n",
        "        scipy.misc.imsave('static/output.png', outputImg)\n",
        "\n",
        "        return jsonify(result=\"Success\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\"\n",
        "\n",
        "  app.run(host=\"0.0.0.0\",port=\"80\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "\n",
        "# Load your dataset of noisy images\n",
        "\n",
        "# Assuming you have a function to load your dataset, e.g., load_dataset()\n",
        "\n",
        "def load_dataset():\n",
        "\n",
        "    # Load and preprocess your dataset here\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "# Define the generator model\n",
        "\n",
        "def build_generator(input_shape):\n",
        "\n",
        "    model = models.Sequential([\n",
        "\n",
        "        layers.Dense(8 * 8 * 128, input_shape=input_shape),\n",
        "\n",
        "        layers.Reshape((8, 8, 128)),\n",
        "\n",
        "        layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same'),\n",
        "\n",
        "        layers.BatchNormalization(),\n",
        "\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "        layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding='same', activation='tanh')\n",
        "\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Define the discriminator model\n",
        "\n",
        "def build_discriminator(input_shape):\n",
        "\n",
        "    model = models.Sequential([\n",
        "\n",
        "        layers.Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=input_shape),\n",
        "\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Conv2D(128, kernel_size=3, strides=2, padding='same'),\n",
        "\n",
        "        layers.BatchNormalization(),\n",
        "\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Flatten(),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Define the GAN model\n",
        "\n",
        "def build_gan(generator, discriminator):\n",
        "\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    model = models.Sequential([\n",
        "\n",
        "        generator,\n",
        "\n",
        "        discriminator\n",
        "\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Define the training loop\n",
        "\n",
        "def train_gan(generator, discriminator, gan, dataset, epochs=100, batch_size=64):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for i in range(0, len(dataset), batch_size):\n",
        "\n",
        "            # Train discriminator\n",
        "\n",
        "            real_images = dataset[i:i+batch_size]\n",
        "\n",
        "            noise = np.random.normal(0, 1, (len(real_images), 100))\n",
        "\n",
        "            generated_images = generator.predict(noise)\n",
        "\n",
        "            labels_real = np.ones((len(real_images), 1))\n",
        "\n",
        "            labels_fake = np.zeros((len(real_images), 1))\n",
        "\n",
        "            discriminator_loss_real = discriminator.train_on_batch(real_images, labels_real)\n",
        "\n",
        "            discriminator_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)\n",
        "\n",
        "            discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "\n",
        "\n",
        "\n",
        "            # Train generator\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "\n",
        "            labels_gen = np.ones((batch_size, 1))\n",
        "\n",
        "            generator_loss = gan.train_on_batch(noise, labels_gen)\n",
        "\n",
        "\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Batch {i + 1}/{len(dataset)}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")\n",
        "\n",
        "\n",
        "\n",
        "# Load and preprocess dataset\n",
        "\n",
        "dataset = load_dataset()\n",
        "\n",
        "\n",
        "\n",
        "# Define input shape\n",
        "\n",
        "input_shape = (64, 64, 1)  # Assuming grayscale images of size 64x64\n",
        "\n",
        "\n",
        "\n",
        "# Build and compile models\n",
        "\n",
        "generator = build_generator(input_shape=(100,))\n",
        "\n",
        "discriminator = build_discriminator(input_shape=input_shape)\n",
        "\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from utils import *\n",
        "\n",
        "from conv_helper import *\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generator(input):\n",
        "\n",
        "    conv1, conv1_weights = conv_layer(input, 9, 3, 32, 1, \"g_conv1\")\n",
        "\n",
        "    conv2, conv2_weights = conv_layer(conv1, 3, 32, 64, 1, \"g_conv2\")\n",
        "\n",
        "    conv3, conv3_weights = conv_layer(conv2, 3, 64, 128, 1, \"g_conv3\")\n",
        "\n",
        "\n",
        "\n",
        "    res1, res1_weights = residual_layer(conv3, 3, 128, 128, 1, \"g_res1\")\n",
        "\n",
        "    res2, res2_weights = residual_layer(res1, 3, 128, 128, 1, \"g_res2\")\n",
        "\n",
        "    res3, res3_weights = residual_layer(res2, 3, 128, 128, 1, \"g_res3\")\n",
        "\n",
        "\n",
        "\n",
        "    deconv1 = deconvolution_layer(res3, [BATCH_SIZE, 128, 128, 64], 'g_deconv1')\n",
        "\n",
        "    deconv2 = deconvolution_layer(deconv1, [BATCH_SIZE, 256, 256, 32], \"g_deconv2\")\n",
        "\n",
        "\n",
        "\n",
        "    deconv2 = deconv2 + conv1\n",
        "\n",
        "\n",
        "\n",
        "    conv4, conv4_weights = conv_layer(deconv2, 9, 32, 3, 1, \"g_conv5\", activation_function=tf.nn.tanh)\n",
        "\n",
        "\n",
        "\n",
        "    conv4 = conv4 + input\n",
        "\n",
        "    output = output_between_zero_and_one(conv4)\n",
        "\n",
        "\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "def discriminator(input, reuse=False):\n",
        "\n",
        "    conv1, conv1_weights = conv_layer(input, 4, 3, 48, 2, \"d_conv1\", reuse=reuse)\n",
        "\n",
        "    conv2, conv2_weights = conv_layer(conv1, 4, 48, 96, 2, \"d_conv2\", reuse=reuse)\n",
        "\n",
        "    conv3, conv3_weights = conv_layer(conv2, 4, 96, 192, 2, \"d_conv3\", reuse=reuse)\n",
        "\n",
        "    conv4, conv4_weights = conv_layer(conv3, 4, 192, 384, 1, \"d_conv4\", reuse=reuse)\n",
        "\n",
        "    conv5, conv5_weights = conv_layer(conv4, 4, 384, 1, 1, \"d_conv5\", activation_function=tf.nn.sigmoid, reuse=reuse)\n",
        "\n",
        "\n",
        "\n",
        "    return conv5\n",
        "\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "generator.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "\n",
        "\n",
        "# Train the GAN\n",
        "\n",
        "train_gan(gen\n",
        "\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "from utils import *\n",
        "\n",
        "from model import *\n",
        "\n",
        "\n",
        "\n",
        "from skimage import measure\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test(image):\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "\n",
        "\n",
        "    global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
        "\n",
        "\n",
        "\n",
        "    gen_in = tf.placeholder(shape=[None, BATCH_SHAPE[1], BATCH_SHAPE[2], BATCH_SHAPE[3]], dtype=tf.float32, name='generated_image')\n",
        "\n",
        "    real_in = tf.placeholder(shape=[None, BATCH_SHAPE[1], BATCH_SHAPE[2], BATCH_SHAPE[3]], dtype=tf.float32, name='groundtruth_image')\n",
        "\n",
        "\n",
        "\n",
        "    Gz = generator(gen_in)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "\n",
        "        sess.run(init)\n",
        "\n",
        "\n",
        "\n",
        "        saver = initialize(sess)\n",
        "\n",
        "        initial_step = global_step.eval()\n",
        "\n",
        "\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        n_batches = 200\n",
        "\n",
        "        total_iteration = n_batches * N_EPOCHS\n",
        "\n",
        "\n",
        "\n",
        "        image = sess.run(tf.map_fn(lambda img: tf.image.per_image_standardization(img), image))\n",
        "\n",
        "        image = sess.run(Gz, feed_dict={gen_in: image})\n",
        "\n",
        "        image = np.resize(image[0][56:, :, :], [144, 256, 3])\n",
        "\n",
        "        imsave('output', image)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "\n",
        "def denoise(image):\n",
        "\n",
        "    image = scipy.misc.imread(image, mode='RGB').astype('float32')\n",
        "\n",
        "    npad = ((56, 56), (0, 0), (0, 0))\n",
        "\n",
        "    image = np.pad(image, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    print(image[0].shape)\n",
        "\n",
        "    output = test(image)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    image = scipy.misc.imread(sys.argv[-1], mode='RGB').astype('float32')\n",
        "\n",
        "    npad = ((56, 56), (0, 0), (0, 0))\n",
        "\n",
        "    image = np.pad(image, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    print(image[0].shape)\n",
        "\n",
        "    test(image)\n",
        "\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "from utils import *\n",
        "\n",
        "from model import *\n",
        "\n",
        "\n",
        "\n",
        "from skimage import measure\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train():\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "\n",
        "\n",
        "    global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
        "\n",
        "\n",
        "\n",
        "    gen_in = tf.placeholder(shape=[None, BATCH_SHAPE[1], BATCH_SHAPE[2], BATCH_SHAPE[3]], dtype=tf.float32, name='generated_image')\n",
        "\n",
        "    real_in = tf.placeholder(shape=[None, BATCH_SHAPE[1], BATCH_SHAPE[2], BATCH_SHAPE[3]], dtype=tf.float32, name='groundtruth_image')\n",
        "\n",
        "\n",
        "\n",
        "    Gz = generator(gen_in)\n",
        "\n",
        "    Dx = discriminator(real_in)\n",
        "\n",
        "    Dg = discriminator(Gz, reuse=True)\n",
        "\n",
        "\n",
        "\n",
        "    real_in_bgr = tf.map_fn(lambda img: RGB_TO_BGR(img), real_in)\n",
        "\n",
        "    Gz_bgr = tf.map_fn(lambda img: RGB_TO_BGR(img), Gz)\n",
        "\n",
        "\n",
        "\n",
        "    psnr=0\n",
        "\n",
        "    ssim=0\n",
        "\n",
        "\n",
        "\n",
        "    d_loss = -tf.reduce_mean(tf.log(Dx) + tf.log(1.-Dg))\n",
        "\n",
        "    g_loss = ADVERSARIAL_LOSS_FACTOR * -tf.reduce_mean(tf.log(Dg)) + PIXEL_LOSS_FACTOR * get_pixel_loss(real_in, Gz) \\\n",
        "\n",
        "             + STYLE_LOSS_FACTOR * get_style_loss(real_in_bgr, Gz_bgr) + SMOOTH_LOSS_FACTOR * get_smooth_loss(Gz)\n",
        "\n",
        "\n",
        "\n",
        "    t_vars = tf.trainable_variables()\n",
        "\n",
        "    d_vars = [var for var in t_vars if 'd_' in var.name]\n",
        "\n",
        "    g_vars = [var for var in t_vars if 'g_' in var.name]\n",
        "\n",
        "\n",
        "\n",
        "    d_solver = tf.train.AdamOptimizer(LEARNING_RATE).minimize(d_loss, var_list=d_vars, global_step=global_step)\n",
        "\n",
        "    g_solver = tf.train.AdamOptimizer(LEARNING_RATE).minimize(g_loss, var_list=g_vars)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "\n",
        "        sess.run(init)\n",
        "\n",
        "\n",
        "\n",
        "        saver = initialize(sess)\n",
        "\n",
        "        initial_step = global_step.eval()\n",
        "\n",
        "\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        n_batches = 200\n",
        "\n",
        "        total_iteration = n_batches * N_EPOCHS\n",
        "\n",
        "\n",
        "\n",
        "        validation_batch = sess.run(tf.map_fn(lambda img: tf.image.per_image_standardization(img), validation))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for index in range(initial_step, total_iteration):\n",
        "\n",
        "            input_batch = load_next_training_batch()\n",
        "\n",
        "            training_batch, groundtruth_batch = np.split(input_batch, 2, axis=2)\n",
        "\n",
        "\n",
        "\n",
        "            training_batch = sess.run(tf.map_fn(lambda img: tf.image.per_image_standardization(img), training_batch))\n",
        "\n",
        "            groundtruth_batch = sess.run(tf.map_fn(lambda img: tf.image.per_image_standardization(img), groundtruth_batch))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            _, d_loss_cur = sess.run([d_solver, d_loss], feed_dict={gen_in: training_batch, real_in: groundtruth_batch})\n",
        "\n",
        "            _, g_loss_cur = sess.run([g_solver, g_loss], feed_dict={gen_in: training_batch, real_in: groundtruth_batch})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            if(index + 1) % SKIP_STEP == 0:\n",
        "\n",
        "\n",
        "\n",
        "                saver.save(sess, CKPT_DIR, index)\n",
        "\n",
        "                image = sess.run(Gz, feed_dict={gen_in: validation_batch})\n",
        "\n",
        "                image = np.resize(image[7][56:, :, :], [144, 256, 3])\n",
        "\n",
        "\n",
        "\n",
        "                imsave('val_%d' % (index+1), image)\n",
        "\n",
        "                image = scipy.misc.imread(IMG_DIR+'val_%d.png' % (index+1), mode='RGB').astype('float32')\n",
        "\n",
        "                psnr = measure.compare_psnr(metrics_image, image, data_range=255)\n",
        "\n",
        "                ssim = measure.compare_ssim(metrics_image, image, multichannel=True, data_range=255, win_size=11)\n",
        "\n",
        "\n",
        "\n",
        "                print(\n",
        "\n",
        "                    \"Step {}/{} Gen Loss: \".format(index + 1, total_iteration) + str(g_loss_cur) + \" Disc Loss: \" + str(\n",
        "\n",
        "                        d_loss_cur)+ \" PSNR: \"+str(psnr)+\" SSIM: \"+str(ssim))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    training_dir_list = training_dataset_init()\n",
        "\n",
        "    validation = load_validation()\n",
        "\n",
        "    train()\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "import re\n",
        "\n",
        "import sys\n",
        "\n",
        "import glob\n",
        "\n",
        "import scipy.misc\n",
        "\n",
        "from itertools import cycle\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from libs import vgg16\n",
        "\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "LEARNING_RATE = 0.002\n",
        "\n",
        "BATCH_SIZE = 5\n",
        "\n",
        "BATCH_SHAPE = [BATCH_SIZE, 256, 256, 3]\n",
        "\n",
        "SKIP_STEP = 10\n",
        "\n",
        "N_EPOCHS = 500\n",
        "\n",
        "CKPT_DIR = './Checkpoints/'\n",
        "\n",
        "IMG_DIR = './Images/'\n",
        "\n",
        "GRAPH_DIR = './Graphs/'\n",
        "\n",
        "TRAINING_SET_DIR= './dataset/training/'\n",
        "\n",
        "# GROUNDTRUTH_SET_DIR='./dataset/groundtruth/'\n",
        "\n",
        "VALIDATION_SET_DIR='./dataset/validation/'\n",
        "\n",
        "METRICS_SET_DIR='./dataset/metrics/'\n",
        "\n",
        "TRAINING_DIR_LIST = []\n",
        "\n",
        "ADVERSARIAL_LOSS_FACTOR = 0.5\n",
        "\n",
        "PIXEL_LOSS_FACTOR = 1.0\n",
        "\n",
        "STYLE_LOSS_FACTOR = 1.0\n",
        "\n",
        "SMOOTH_LOSS_FACTOR = 1.0\n",
        "\n",
        "metrics_image = scipy.misc.imread(METRICS_SET_DIR+'gt.png', mode='RGB').astype('float32')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def initialize(sess):\n",
        "\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    writer = tf.summary.FileWriter(GRAPH_DIR, sess.graph)\n",
        "\n",
        "\n",
        "\n",
        "    if not os.path.exists(CKPT_DIR):\n",
        "\n",
        "        os.makedirs(CKPT_DIR)\n",
        "\n",
        "    if not os.path.exists(IMG_DIR):\n",
        "\n",
        "        os.makedirs(IMG_DIR)\n",
        "\n",
        "\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(os.path.dirname(CKPT_DIR))\n",
        "\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "\n",
        "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "\n",
        "    return saver\n",
        "\n",
        "\n",
        "\n",
        "def get_training_dir_list():\n",
        "\n",
        "    training_list = [d[1] for d in os.walk(TRAINING_SET_DIR)]\n",
        "\n",
        "    global TRAINING_DIR_LIST\n",
        "\n",
        "    TRAINING_DIR_LIST = training_list[0]\n",
        "\n",
        "    return TRAINING_DIR_LIST\n",
        "\n",
        "\n",
        "\n",
        "def load_next_training_batch():\n",
        "\n",
        "    batch = next(pool)\n",
        "\n",
        "\n",
        "\n",
        "    # filelist = sorted(glob.glob(TRAINING_SET_DIR+ batch +'/*.png'), key=alphanum_key)\n",
        "\n",
        "    # batch = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "\n",
        "    # npad =((0, 0), (56, 56), (0, 0), (0, 0))\n",
        "\n",
        "    # batch = np.pad(batch, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "    return batch\n",
        "\n",
        "\n",
        "\n",
        "# def load_groundtruth():\n",
        "\n",
        "#     filelist = sorted(glob.glob(GROUNDTRUTH_SET_DIR + '/*.png'), key=alphanum_key)\n",
        "\n",
        "#     groundtruth = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "\n",
        "#     # npad = ((0, 0), (56, 56), (0, 0), (0, 0))\n",
        "\n",
        "#     # groundtruth = np.pad(groundtruth, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "#     return groundtruth\n",
        "\n",
        "\n",
        "\n",
        "def load_validation():\n",
        "\n",
        "    filelist = sorted(glob.glob(VALIDATION_SET_DIR + '/*.png'), key=alphanum_key)\n",
        "\n",
        "    validation = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "\n",
        "    npad = ((0, 0), (56, 56), (0, 0), (0, 0))\n",
        "\n",
        "    validation = np.pad(validation, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "    return validation\n",
        "\n",
        "\n",
        "\n",
        "def training_dataset_init():\n",
        "\n",
        "    filelist = sorted(glob.glob(TRAINING_SET_DIR + '/*.png'), key=alphanum_key)\n",
        "\n",
        "    batch = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "\n",
        "    batch = split(batch, BATCH_SIZE)\n",
        "\n",
        "    training_dir_list = get_training_dir_list()\n",
        "\n",
        "    global pool\n",
        "\n",
        "    pool = cycle(batch)\n",
        "\n",
        "    # return training_dir_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def imsave(filename, image):\n",
        "\n",
        "    scipy.misc.imsave(IMG_DIR+filename+'.png', image)\n",
        "\n",
        "\n",
        "\n",
        "def merge_images(file1, file2):\n",
        "\n",
        "    \"\"\"Merge two images into one, displayed side by side\n",
        "\n",
        "    :param file1: path to first image file\n",
        "\n",
        "    :param file2: path to second image file\n",
        "\n",
        "    :return: the merged Image object\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    image1 = Image.fromarray(np.uint8(file1))\n",
        "\n",
        "    image2 = Image.fromarray(np.uint8(file2))\n",
        "\n",
        "\n",
        "\n",
        "    (width1, height1) = image1.size\n",
        "\n",
        "    (width2, height2) = image2.size\n",
        "\n",
        "\n",
        "\n",
        "    result_width = width1 + width2\n",
        "\n",
        "    result_height = max(height1, height2)\n",
        "\n",
        "\n",
        "\n",
        "    result = Image.new('RGB', (result_width, result_height))\n",
        "\n",
        "    result.paste(im=image1, box=(0, 0))\n",
        "\n",
        "    result.paste(im=image2, box=(width1, 0))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tryint(s):\n",
        "\n",
        "    try:\n",
        "\n",
        "        return int(s)\n",
        "\n",
        "    except:\n",
        "\n",
        "        return s\n",
        "\n",
        "\n",
        "\n",
        "def alphanum_key(s):\n",
        "\n",
        "    \"\"\" Turn a string into a list of string and number chunks.\n",
        "\n",
        "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def split(arr, size):\n",
        "\n",
        "    arrs = []\n",
        "\n",
        "    while len(arr) > size:\n",
        "\n",
        "        pice = arr[:size]\n",
        "\n",
        "        arrs.append(pice)\n",
        "\n",
        "        arr = arr[size:]\n",
        "\n",
        "    arrs.append(arr)\n",
        "\n",
        "    return arrs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def lrelu(x, leak=0.2, name='lrelu'):\n",
        "\n",
        "    with tf.variable_scope(name):\n",
        "\n",
        "        f1 = 0.5 * (1 + leak)\n",
        "\n",
        "        f2 = 0.5 * (1 - leak)\n",
        "\n",
        "        return f1 * x + f2 * abs(x)\n",
        "\n",
        "\n",
        "\n",
        "def RGB_TO_BGR(img):\n",
        "\n",
        "    img_channel_swap = img[..., ::-1]\n",
        "\n",
        "    # img_channel_swap_1 = tf.reverse(img, axis=[-1])\n",
        "\n",
        "    return img_channel_swap\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_pixel_loss(target,prediction):\n",
        "\n",
        "    pixel_difference = target - prediction\n",
        "\n",
        "    pixel_loss = tf.nn.l2_loss(pixel_difference)\n",
        "\n",
        "    return pixel_loss\n",
        "\n",
        "\n",
        "\n",
        "def get_style_layer_vgg16(image):\n",
        "\n",
        "    net = vgg16.get_vgg_model()\n",
        "\n",
        "    style_layer = 'conv2_2/conv2_2:0'\n",
        "\n",
        "    feature_transformed_image = tf.import_graph_def(\n",
        "\n",
        "        net['graph_def'],\n",
        "\n",
        "        name='vgg',\n",
        "\n",
        "        input_map={'images:0': image},return_elements=[style_layer])\n",
        "\n",
        "    feature_transformed_image = (feature_transformed_image[0])\n",
        "\n",
        "    return feature_transformed_image\n",
        "\n",
        "\n",
        "\n",
        "def get_style_loss(target,prediction):\n",
        "\n",
        "    feature_transformed_target = get_style_layer_vgg16(target)\n",
        "\n",
        "    feature_transformed_prediction = get_style_layer_vgg16(prediction)\n",
        "\n",
        "    feature_count = tf.shape(feature_transformed_target)[3]\n",
        "\n",
        "    style_loss = tf.reduce_sum(tf.square(feature_transformed_target-feature_transformed_prediction))\n",
        "\n",
        "    style_loss = style_loss/tf.cast(feature_count, tf.float32)\n",
        "\n",
        "    return style_loss\n",
        "\n",
        "\n",
        "\n",
        "def get_smooth_loss(image):\n",
        "\n",
        "    batch_count = tf.shape(image)[0]\n",
        "\n",
        "    image_height = tf.shape(image)[1]\n",
        "\n",
        "    image_width = tf.shape(image)[2]\n",
        "\n",
        "\n",
        "\n",
        "    horizontal_normal = tf.slice(image, [0, 0, 0,0], [batch_count, image_height, image_width-1,3])\n",
        "\n",
        "    horizontal_one_right = tf.slice(image, [0, 0, 1,0], [batch_count, image_height, image_width-1,3])\n",
        "\n",
        "    vertical_normal = tf.slice(image, [0, 0, 0,0], [batch_count, image_height-1, image_width,3])\n",
        "\n",
        "    vertical_one_right = tf.slice(image, [0, 1, 0,0], [batch_count, image_height-1, image_width,3])\n",
        "\n",
        "    smooth_loss = tf.nn.l2_loss(horizontal_normal-horizontal_one_right)+tf.nn.l2_loss(vertical_normal-vertical_one_right)\n",
        "\n",
        "    return smooth_loss\n",
        "\n",
        "\n",
        "\n",
        "erator, discriminator, gan, dataset)"
      ]
    }
  ]
}